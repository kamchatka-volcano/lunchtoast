# Hello, this config file will show you how to create lunchtoast test cases! This is a comment, by the way.
# (lunchtoast only supports commenting out the whole lines, by starting them with '#')

# The lunchtoast test case file consists of multiple sections, used to set up test parameters and actions.
# Sections are created by starting the line with '-' following by section's names and parameters, and delimiting section's value with ':'(must be on the same line as section's name). 
# -Name: Hello World
# In this example name is the section's name, 'Hello World' - is a section's value.
# (section's value is everything between ':' and the start of the next section, or the end of the file)
#
# Raw sections are sections that can have lines starting with '#' and '-' in their values. 
# Raw sections are closed by the '---' sequence, or the end of the file.
# -Write test.txt:
# Hello world
# #Yes
# -No
# ---
# In this example, 'Write' is the section's name, 'test.txt' is the section's parameter, and 3 lines between ':' and '---' are the section's value.

##########################
### PARAMETER SECTIONS ###
##########################

# Name, sets the name of the current test. The default value is the name of the test case file.
-Name: Example test

# Description, sets the text information about the test that is shown in the report for failed tests. 
-Description: This test case file describes all available parameters and actions. It has a valid configuration and should pass if you run it from the examples directory.

# Suite, sets the name of the test suite. The default value is the name of the directory where the test case file resides.
-Suite: Example suite

# Macro variables
# Three parameters described above can be used with the following macro variables:  
# ${{ DIR }} - the name of the directory where the test test case file resides and
# ${{ FILENAME }} - the name of the test case file without the extension
# For example, they can be used like this:
# -Decription: ${{ FILENAME }}
# or
# -Suite: suite_${{ DIR }}

# Directory, sets the test directory, all non-absolute paths in this config are relative to it. 
# The default value is the directory where the test case file resides. If the value is a non-absolute path, it's relative to the default value's path.
-Directory: readme_test

#Enabled, enables test. The default value is "true". Any other value, disables the test.
-Enabled: true

#Cleanup, on succefull test run, enables cleanup of all files and directories that weren't present in the test directory before the test was started.
# The default value is false; To enable, set it to "true", any other value is treated as false.
-Cleanup: true

#Cleanup whitelist, if present and not empty, modifies behaviour of the cleanup parameter. All files present in the test directory, 
# but not specified in whitelist are deleted before the test is started and after it finished successfuly.
# The parameter's value should be a list of files, directories and file-matching regular expression (surround with braces).
# The test case file is put on whitelist by default and can be omitted.
-Cleanup whitelist: {.*\.ref} readme_proc.sh

#Shell, sets the shell command that is used for launching commands (will be described lately)
#The default value is "sh -c -e"
-Shell: sh -c -e

#########################
###  ACTION SECTIONS  ###
#########################

# Launch, launches the process, waits for its completion and checks the exit code, if it differs from 0, the action is considered a failure and the test execution stops.
# Launch parameters:
#   unchecked - doesn't check the return code, the test doesn't stop if launching fails
#   command - launchs the process in system shell
#   silently - drops the standard output from the test report
# Parameters can be specified in any order and have any strings in between them, for example:
# -Launch command unchecked and silently: echo "0" > test.txt
-Launch command: readme_proc.sh > test.res

# Write, writes the section value to the file specified in the first section's parameter. 
# (note this is the raw section, you must put '---' after the last line of the section's value text)
-Write test2.res:
Hello world2
---

#Assert content of, checks the content of file, specified in the first section's parameter, with the section's value. If they differ, the action is considered a failure and the test execution stops.
# (note that this is the raw section, you must put '---' after the last line of the section's value text)
-Assert test.res:
Hello world
---

#Expect content of, checks the content of file, specified in the first section's parameter, with the section's value. If they differ, the test is considered a failure, but it continues to execute the next available actions.
# (note that this is the raw section, you must put '---' after the last line of the section's value text)
-Expect test2.res:
Hello world2
---

# Assert files equal, checks that two files specified in section's value are equal. If they differ, the action is considered a failure and the test execution stops.
-Assert files equal: test.res test.ref
# It's also possible to compare two file lists by using file matching regular expressions.
-Assert files equal: {.*\.res} {.*\.ref}

# Expect files equal, checks that two files specified in section's value are equal. If they differ, the test is considered a failure, but it continues to execute the next available actions.
-Expect files equal: test2.res test2.ref
# It's also possible to compare two file lists by using file matching regular expressions.
-Expect files equal: {.*\.res} {.*\.ref}

# That's it!
